{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation and Analysis with Pandas\n",
    "By Eli Yi-Liang Tung \n",
    "\n",
    "Department of Analytics and Operations, Business School, NUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "1. What is Pandas package? \n",
    "2. Import data into Python\n",
    "3. Basic components of DataFrame and Series\n",
    "4. Basic data manipulation\n",
    "    * Access data\n",
    "    * Filter/subset data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import your data into Python \n",
    "To start your data analytics project, the first thing is that you are able to import your raw data into Python system. Before that, let's find out the current working directory using `os` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting your working directory, **you must move your raw data file into the working directory and then Python will know where to find your data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief introduction to `Pandas` package\n",
    "- Pandas is an open-source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "- Developed by Wes McKinney since 2008.\n",
    "- The package’s name derives from <i>`panel data`</i>, a common term for multidimensional data sets encountered in statistics and econometrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides a lot of methods to import external data sources into Python. Here we just need to work on  `.csv ` file. Let's use `read_csv()` method from Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import `ChallengerSales.csv` into Python and do basic data manipulation to understand the sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ChallengerSales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(5)    # head() method can show several rows of the data imported for checking purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)    # tail() method can show last several rows of the data imported "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check all the data types in the df DataFrame, you can use **dtypes**, an attribute of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values    #Result is a 2-D Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, in the df DataFrame, there are 400 rows and 10 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Data Structures in Pandas\n",
    "There are two main data structures designed by Pandas. \n",
    "- **Series**\n",
    "    * 1-D array of labelled data \n",
    "    * Series can be viewed as a hybrid of a 1-D Numpy ndarray with row index labels \n",
    "    * There is no columns attribute for a Series.\n",
    "\n",
    "- **DataFrame**\n",
    "    * A labelled 2-D array of data\n",
    "    * Each column is a Series sharing common row labels\n",
    "    * Two key components to label each data point: column name and index label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's discuss DataFrame first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DataFrame.jpg\" alt=\"Pandas Data Frame\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The term index refers to all the index labels of the DataFrame\n",
    "- The term columns refers to all the column names of the DataFrame  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Data Types in Pandas\n",
    "\n",
    "The table below is from Pandas Cookbook by Theodore Petrou."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DataTypes.jpg\" alt=\"Pandas Data Frame\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes of Data Types:\n",
    "<n>\n",
    "- Each DataFrame column must exactly one type of data. \n",
    "- Pandas defaults its numeric data, integers and floats to 64 bits.\n",
    "- When a column is of the object data type, it signals that the entire column is strings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we discuss Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series by selecting a column from df DataFrame \n",
    "total_cost = df['TotalCost']\n",
    "type(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost.columns    # No .columns attribute is associated with a Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cost.values    # Result is a 1-D Numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data manipulation using Pandas\n",
    "To learn Pandas, the first task is that you can assess the data stored in the Dataframe. Again, we can apply indexing and slicing to access the data you need. However, remember Pandas Series and DataFrame are labelled data; there are specific methods that can utilize labelled data for data manipulation.   \n",
    "### Get data elements using `Indexing Operator`\n",
    "Our focus is on working with DataFrame, a labelled 2-D array of data. For DataFrame, each column, in fact, is a Pandas Series and all columns share common row index labels.\n",
    "#### Access the whole column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can apply indexing. However the first set of square brackets refers to column name \n",
    "# Recall that you can view column name as a dictionary's key\n",
    "\n",
    "region = df['Region']    # Access the whole Region column of the df DataFrame\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Region','Day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[['Region','Day']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access a specific element:\n",
    "Similar to a Dictionary object, you need to identify column name (key) first and use the second set of square brackets to find out the location of the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transaction record in row 6 and \"Region\" column\n",
    "# Recall that Python uses zero-based indexing\n",
    "print(df['Region'][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access several multiple columns at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a string list including the names of the columns needed \n",
    "cols_need = ['Gender', 'Member', 'Region', 'TotalCost']\n",
    "df_short = df[cols_need]\n",
    "df_short.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixed with slicing operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine slicing to obtain the odd rows of the data set only\n",
    "df_short2 = df[cols_need][::2]   # start:end:step_size, note that \"end\" is exclusive\n",
    "df_short2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data elements using `Indexer Attribute`\n",
    "As mentioned, DataFrame is a labelled data container. To deal with labels, Pandas also provides indexers, one of the attributes of a DataFrame. There are two types of indexers defined in Pandas: `.loc` and `.iloc` indexers. \n",
    "* *.loc indexer*, which uses row index and column name to identify data elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To use the `.loc` indexer, you must input the `exact` row and column labels. Otherwise, you will encounter errors. \n",
    "2. Only one set of square brackets [] is needed.\n",
    "3. When you apply the `.loc` indexer, please do remember that the first argument is `the row index`, followed by `the column name`, and you use a comma to separate them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful that we need to specify row index first followed by column name\n",
    "print(df.loc[5,'Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not input the column name, the whole row will be selected by default\n",
    "row_6 = print(df.loc[5])    # Get row 6 (the corresponding row index is 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the whole \"Region\" column\n",
    "# Shorthand for selecting \"all\" is a colon mark. Here we want to select all rows\n",
    "df_demo1= df.loc[:,'Region']\n",
    "print(df_demo1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_need = ['Gender', 'Member', 'Region', 'TotalCost']\n",
    "df_demo2 = df.loc[::2, cols_need]\n",
    "print(df_demo2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_need = ['Gender', 'Member', 'Region', 'TotalCost']\n",
    "rows_need = [0, 5, 8, 100]\n",
    "df_demo3 = df.loc[rows_need, cols_need]\n",
    "print(df_demo3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a wrong column name. You must provide the “exact” row index and column name\n",
    "print(df.loc[5,'region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *iloc indexer*, which uses positional indices to identify elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you apply the `iloc` indexer, please do remember that the first argument is the row index, followed by the column index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again do not forget zero-based indexing\n",
    "print(df.iloc[5, 3])   # row 6 and column 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 10 columns in the df DataFrame. Thus, the range of column indices is from 0 to 9\n",
    "print(df.iloc[5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You cannot use a mixing input style\n",
    "# If you want to use .iloc indexer, all the inputs must be positional indices\n",
    "cols_need = ['Gender', 'Member', 'Region', 'TotalCost']\n",
    "df_redu = df.iloc[:, cols_need]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_need = ['Gender', 'Member', 'Region', 'TotalCost']\n",
    "cols_index = [3, -2, -1, -4]\n",
    "df_redu = df.iloc[:, cols_index]\n",
    "print(df_redu.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Key Difference between .loc and .iloc when using slicing operators\n",
    "\n",
    "When using `.loc` indexer, the slicing operator behaves differently from the standard slicing operator. **The ending label is inclusive.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:5, 2:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0:5,'Time':'TotalCost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify columns in the DataFrame\n",
    "You can add new columns into an existing DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a new column\n",
    "The sytax is very similar to the way we add a key into a dictionary. \n",
    "\n",
    "Moreover, Pandas package is built on the well-known Numpy package as its core. Thus, Pandas also supports element-wise operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AvecostItem'] = 0    # Add a new column with column name \"AvecostItem\" and initialize values to be zero\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'AvecostItem', which represents the total cost of a trasaction / the items ordered in that transaction\n",
    "df['AvecostItem'] = df['TotalCost']/df['ItemsOrdered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering via Boolean Indexing\n",
    "- The most useful data filtering technique in Pandas is Boolean indexing.\n",
    "- Boolean indexing refers to selecting rows of a DataFrame by providing a Boolean value for each row.\n",
    "- These Boolean values are stored in a Series or a Numpy’s ndarray and are created by applying logical/comparison operators.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Question:</i> We want to know the number of transactions from the West region?\n",
    "\n",
    "- <i>Step 1:</i> Create a Boolean Series to satisfy the `filtering criterion/condition`. We call this Boolean Series `a Filter`.\n",
    "- <i>Step 2:</i> Use the filter and apply indexing operator or indexers to subset the original data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the filter, Boolean Series\n",
    "west_filter = df['Region'] == 'West'  # We call this Boolean Series as a filter\n",
    "print(west_filter.head(10),\"\\n\")\n",
    "print(df['Region'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2(Method 1): Subset your data by using indexing operator\n",
    "west_df_1 = df[:][west_filter]\n",
    "print(west_df_1.shape, \"\\n\")\n",
    "print(west_df_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2(Method 2): Subset your data by using .loc indexer\n",
    "west_df_2 = df.loc[west_filter, :]\n",
    "print(west_df_2.shape, \"\\n\")\n",
    "print(west_df_2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2(Method 3): Subset your data by using .iloc indexer\n",
    "west_df_3 = df.iloc[west_filter, :]\n",
    "print(west_df_3.shape, \"\\n\")\n",
    "print(west_df_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_filter.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_df_3 = df.iloc[west_filter.values, :]\n",
    "print(west_df_3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_df_3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_count is a Series method, no such method for a DataFrame\n",
    "west_df_3[\"Gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_df_3[\"Gender\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Question:</i> Among transactions with a total cost larger than 150, what is the gender by region composition in you data? \n",
    "\n",
    "We can consider more than one filtering condition at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criter1 = df[\"TotalCost\"] > 150     # Create the first filter, the result is a Boolean Series\n",
    "criter2 = df[\"Region\"] == \"West\"    # Create the second filter, only transactions from West will be True\n",
    "\n",
    "print(df[[\"TotalCost\", \"Region\"]].tail(5), \"\\n\") # From df, we just select two columns of interest and show last 5 rows \n",
    "print(criter1.tail(5), \"\\n\")                     # Check first filter and again just show last 5 rows \n",
    "print(criter2.tail(5))                           # Check second filter and show last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criter1 and criter2     # \"and\" operator can be applied only to basic Python variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitwise Operators (&, |,  ~)\n",
    "- In forming Boolean Series in Pandas, we cannot use <i>**and**, **or** and **not**</i> to do logical comparisons. We must use bitwise operators instead.\n",
    "- For each filtering condition, we must use round brackets () to enclose it.\n",
    "- There are three bitwise operators you will use in Pandas:\n",
    "    1. **&**: the same as and\n",
    "    2. **|**: the same as or\n",
    "    3. **~**: the same as not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inters_c1_c2 = criter1 & criter2 \n",
    "inters_c1_c2 = (df[\"TotalCost\"] > 150) & (df[\"Region\"] == \"West\")\n",
    "print(f\"The number of transactions that meet the two filtering conditions is {inters_c1_c2.sum()}.\", \"\\n\")\n",
    "\n",
    "print(df[[\"TotalCost\", \"Region\"]].tail(5), \"\\n\") # From df, we just select two columns of interest and show last 5 rows \n",
    "inters_c1_c2.tail(5)                             # check the intersection of both filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df.loc[inters_c1_c2,:]                 # Subset data to include only transactions with total amount > 150, from West  \n",
    "dft[\"Gender\"].value_counts(normalize = True) # Find out gender proportions in the filtered data\n",
    "\n",
    "# Using method chaining \n",
    "df.loc[inters_c1_c2,:][\"Gender\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to find out gender proportions across different regions\n",
    "print(df[\"Region\"].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Find out unique values in the Region column\n",
    "uni_region = df[\"Region\"].unique()\n",
    "print(uni_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1: Above is the code to create an empty dictionary with 4 keys and all corresponding values are empty lists\n",
    "\n",
    "output = {'West': list(),\n",
    "          'East': list(),\n",
    "          'South': list(),\n",
    "          'Central': list()}\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: another way of creating an empty dictionary\n",
    "uni_region = df[\"Region\"].unique()     # Find out unique values in the Region column\n",
    "output = {}\n",
    "for reg in uni_region:\n",
    "    output.update({str(reg): list()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criter1 = df[\"TotalCost\"] > 150\n",
    "for i in range(len(uni_region)):                # Use a for loop to loop over all possible regions \n",
    "    criter2 = (df[\"Region\"] == uni_region[i])   # For each region, we create a region-specific filter\n",
    "    joint_criter = criter1 & criter2 \n",
    "    dfsubset = df.loc[joint_criter, :].copy()          # Subset data from each region\n",
    "    dfs_prop = dfsubset[\"Gender\"].value_counts(normalize = True)\n",
    "    output[uni_region[i]] = dfs_prop            # Assign the computaion result to a key in the output dictionary\n",
    "    \n",
    "result = pd.DataFrame(output)   # Make a DateFrame for presentation\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't enclose each filtering condition, you will encounter errors\n",
    "criter1 = df[\"TotalCost\"] > 100 & df[\"TotalCost\"] <= 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>Question:</i> \n",
    "<n>\n",
    "Let’s define a transaction amount between 50 and 400 as a regular transaction. Moreover, we exclude transactions with a single item and focus on the female customers only. For those female customers, do they have any preferred shopping time period in a day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criter1 = (df[\"TotalCost\"] > 50) & (df[\"TotalCost\"] <= 400) # filter 1: 50 < TotalCost <= 400\n",
    "criter2 = df[\"ItemsOrdered\"] > 1                            # filter 2: the number of items > 1\n",
    "criter3 = df[\"Gender\"] == \"Female\"                          # filter 3: transactions made by female customers\n",
    "\n",
    "joint_crit = criter1 & criter2 & criter3                    # Consider 3 filtering conditions at the same time\n",
    "dfQ3 = df.iloc[joint_crit.values,:]\n",
    "dfQ3[\"Time\"].value_counts(normalize = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
